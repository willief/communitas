name: Performance Monitoring

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run performance monitoring weekly on Saturdays at 6 AM UTC
    - cron: "0 6 * * 6"
  workflow_dispatch:
    inputs:
      num_nodes:
        description: 'Number of P2P nodes to test'
        required: false
        default: '5'
      test_duration:
        description: 'Test duration in seconds'
        required: false
        default: '120'

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  RUST_LOG: info

jobs:
  p2p-multi-node-performance:
    name: P2P Multi-Node Performance Test
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      matrix:
        scenario:
          - { nodes: 2, duration: 60, name: "minimal" }
          - { nodes: 3, duration: 90, name: "small" }
          - { nodes: 5, duration: 120, name: "standard" }

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: . -> target

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libwebkit2gtk-4.1-dev \
            libgtk-3-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            netcat-openbsd \
            jq

      - name: Build communitas-headless
        run: |
          cd communitas-headless
          cargo build --release --bin communitas-headless
          ls -la target/release/
          echo "Binary size: $(du -h target/release/communitas-headless | cut -f1)"
          # Copy the binary to the expected location for the script
          mkdir -p ../target/release/
          cp target/release/communitas-headless ../target/release/communitas-headless
          echo "Binary copied to root target/release/"

      - name: Make test script executable
        run: chmod +x scripts/p2p-performance-test.sh

      - name: Run P2P Performance Test (${{ matrix.scenario.name }})
        env:
          NUM_NODES: ${{ matrix.scenario.nodes }}
          TEST_DURATION: ${{ matrix.scenario.duration }}
          LOG_DIR: /tmp/communitas-perf-${{ matrix.scenario.name }}
          BINARY_PATH: communitas-headless/target/release/communitas-headless
        run: |
          echo "Running ${{ matrix.scenario.name }} scenario with ${{ matrix.scenario.nodes }} nodes"
          ./scripts/p2p-performance-test.sh

      - name: Analyze Performance Results
        if: always()
        run: |
          LOG_DIR="/tmp/communitas-perf-${{ matrix.scenario.name }}"
          
          if [ -f "$LOG_DIR/summary.json" ]; then
            echo "Performance Summary:"
            cat "$LOG_DIR/summary.json" | jq '.'
            
            # Extract key metrics
            FORMATION_TIME=$(cat "$LOG_DIR/summary.json" | jq -r '.formation_time // "N/A"')
            AVG_PEERS=$(cat "$LOG_DIR/summary.json" | jq -r '.average_peers // "0"')
            
            echo "## Performance Metrics for ${{ matrix.scenario.name }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Nodes**: ${{ matrix.scenario.nodes }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Formation Time**: ${FORMATION_TIME}s" >> $GITHUB_STEP_SUMMARY
            echo "- **Average Peers**: ${AVG_PEERS}" >> $GITHUB_STEP_SUMMARY
            
            # Check performance thresholds
            if [ "$FORMATION_TIME" != "N/A" ] && [ "$FORMATION_TIME" -gt 30 ]; then
              echo "⚠️ Network formation took longer than 30s"
              exit 1
            fi
          else
            echo "❌ No performance summary found"
            exit 1
          fi

      - name: Upload Performance Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-logs-${{ matrix.scenario.name }}
          path: /tmp/communitas-perf-${{ matrix.scenario.name }}/
          retention-days: 7

  real-world-simulation:
    name: Real-World P2P Simulation
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: p2p-multi-node-performance

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: . -> target

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libwebkit2gtk-4.1-dev \
            libgtk-3-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            iperf3 \
            tc

      - name: Build communitas-headless
        run: |
          cd communitas-headless
          cargo build --release --bin communitas-headless

      - name: Simulate Network Conditions
        run: |
          echo "Testing P2P performance under various network conditions..."
          
          # Create test script for network simulation
          cat > /tmp/network-sim.sh << 'EOF'
          #!/bin/bash
          set -e
          
          BINARY="./target/release/communitas-headless"
          BASE_PORT=10000
          
          echo "=== Testing under normal conditions ==="
          timeout 30s $BINARY --listen 127.0.0.1:$BASE_PORT --metrics --metrics-addr 127.0.0.1:10600 > /tmp/node-normal.log 2>&1 &
          PID=$!
          sleep 5
          
          # Check if node started successfully
          if curl -s http://127.0.0.1:10600/health > /dev/null 2>&1; then
            echo "✓ Node started successfully under normal conditions"
          else
            echo "✗ Node failed to start"
          fi
          
          kill $PID 2>/dev/null || true
          wait $PID 2>/dev/null || true
          
          echo ""
          echo "=== Testing with high CPU load ==="
          # Simulate high CPU load
          stress-ng --cpu 2 --timeout 10s &
          STRESS_PID=$!
          
          timeout 30s $BINARY --listen 127.0.0.1:$((BASE_PORT+1)) --metrics --metrics-addr 127.0.0.1:10601 > /tmp/node-stress.log 2>&1 &
          PID=$!
          sleep 5
          
          if curl -s http://127.0.0.1:10601/health > /dev/null 2>&1; then
            echo "✓ Node started successfully under CPU stress"
          else
            echo "✗ Node failed under CPU stress"
          fi
          
          kill $PID 2>/dev/null || true
          kill $STRESS_PID 2>/dev/null || true
          wait
          
          echo ""
          echo "=== Performance comparison ==="
          echo "Normal conditions log lines: $(wc -l < /tmp/node-normal.log)"
          echo "Stress conditions log lines: $(wc -l < /tmp/node-stress.log)"
          EOF
          
          chmod +x /tmp/network-sim.sh
          
          # Install stress-ng if available
          sudo apt-get install -y stress-ng || echo "stress-ng not available"
          
          cd communitas-headless
          BINARY_PATH="./target/release/communitas-headless" /tmp/network-sim.sh || true

      - name: Collect System Metrics
        run: |
          echo "## System Performance Metrics" >> $GITHUB_STEP_SUMMARY
          echo "- **CPU Cores**: $(nproc)" >> $GITHUB_STEP_SUMMARY
          echo "- **Memory**: $(free -h | grep Mem | awk '{print $2}')" >> $GITHUB_STEP_SUMMARY
          echo "- **Kernel**: $(uname -r)" >> $GITHUB_STEP_SUMMARY

  benchmark-critical-paths:
    name: Benchmark Critical Code Paths
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: . -> target

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libwebkit2gtk-4.1-dev \
            libgtk-3-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev

      - name: Run Benchmarks
        run: |
          echo "Running performance benchmarks..."
          
          # Run any existing benchmarks
          if cargo bench --no-run 2>/dev/null; then
            cargo bench --bench '*' -- --output-format bencher | tee benchmark_results.txt || true
            
            if [ -f benchmark_results.txt ]; then
              echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              head -20 benchmark_results.txt >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "No benchmarks configured yet"
          fi

      - name: Profile Critical Functions
        run: |
          echo "Profiling critical functions..."
          
          # Create a simple profiling test
          cat > /tmp/profile_test.rs << 'EOF'
          use std::time::Instant;
          
          fn main() {
              // Test container operations
              let start = Instant::now();
              for _ in 0..1000 {
                  let _ = vec![0u8; 1024];
              }
              let alloc_time = start.elapsed();
              
              println!("Allocation time for 1000x1KB: {:?}", alloc_time);
              
              if alloc_time.as_millis() > 100 {
                  eprintln!("Warning: Allocation performance below threshold");
              }
          }
          EOF
          
          rustc -O /tmp/profile_test.rs -o /tmp/profile_test
          /tmp/profile_test

  performance-regression-check:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: . -> target

      - name: Build and measure compile time
        run: |
          echo "Measuring build performance..."
          
          # Clean build
          cargo clean
          
          # Measure debug build time
          START=$(date +%s)
          cargo build --package communitas-headless
          END=$(date +%s)
          DEBUG_TIME=$((END - START))
          
          # Measure release build time
          START=$(date +%s)
          cargo build --release --package communitas-headless
          END=$(date +%s)
          RELEASE_TIME=$((END - START))
          
          echo "## Build Performance" >> $GITHUB_STEP_SUMMARY
          echo "- Debug build: ${DEBUG_TIME}s" >> $GITHUB_STEP_SUMMARY
          echo "- Release build: ${RELEASE_TIME}s" >> $GITHUB_STEP_SUMMARY
          
          # Check against thresholds
          if [ $RELEASE_TIME -gt 600 ]; then
            echo "⚠️ Release build time exceeds 10 minutes"
          fi

      - name: Check binary size
        run: |
          BINARY_SIZE=$(stat -c%s target/release/communitas-headless)
          BINARY_SIZE_MB=$((BINARY_SIZE / 1024 / 1024))
          
          echo "## Binary Size" >> $GITHUB_STEP_SUMMARY
          echo "- Release binary: ${BINARY_SIZE_MB}MB" >> $GITHUB_STEP_SUMMARY
          
          if [ $BINARY_SIZE_MB -gt 50 ]; then
            echo "⚠️ Binary size exceeds 50MB threshold"
          fi

  report-summary:
    name: Performance Report Summary
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [p2p-multi-node-performance, benchmark-critical-paths]
    if: always()

    steps:
      - name: Generate Performance Report
        run: |
          echo "# Performance Monitoring Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.p2p-multi-node-performance.result }}" == "success" ]; then
            echo "✅ P2P Multi-Node Tests: **Passed**" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ P2P Multi-Node Tests: **Failed**" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.benchmark-critical-paths.result }}" == "success" ]; then
            echo "✅ Benchmark Tests: **Passed**" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Benchmark Tests: **Failed**" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Performance monitoring completed*" >> $GITHUB_STEP_SUMMARY